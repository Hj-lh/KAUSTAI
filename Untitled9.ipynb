{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeHkLSC9UPcUyUrHmsXtE7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"Dp1i8bNFLCqh","executionInfo":{"status":"ok","timestamp":1700541904614,"user_tz":-180,"elapsed":2469,"user":{"displayName":"am4 _m03","userId":"03884497344136522816"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from copy import deepcopy\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","source":["def plotClass(X,y,p):\n","    for i in range(y.shape[1]):\n","        if y[0,i]==0:\n","            plt.plot(X[0,i],X[1,i],'r'+p)\n","        else:\n","            plt.plot(X[0,i],X[1,i],'b'+p)\n","\n","def sigmoid(z):\n","    \"\"\"\n","    Apply sigmoid function. Sigmoid brings the output in 0 to 1 range\n","    \"\"\"\n","    return 1 / (1 + np.exp(-z))\n","\n","\n","def log_reg_cost(y, y_pred):  # cross entropy\n","    \"\"\"\n","    Calculates and returns the cost for logistic regression.\n","\n","    Function is slightly different from mentioned above because this one handles batched/vector/multiple inputs (rather than just one).\n","    This function sums and takes average across the vector.\n","    \"\"\"\n","\n","    cost = -1/len(y) * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n","\n","    return cost\n","\n","\n","def log_reg_gradient_descent(X, y, learning_rate, n_iters=500):\n","    \"\"\"\n","    Runs gradient descent (param optimization) for logistic regression and returns optimized weights.\n","    \"\"\"\n","    m, n = x.shape  #m: the number of samples, n: the number of features in x\n","    theta = np.zeros(n) # theta is initialized with zeros\n","\n","    losses = []\n","\n","    \"\"\"\n","     tqdm: is similar to loop but with more benefits like\n","     progress bar and Estimation of Remaining Time\n","\n","     gradient: see main_notes page#22 and 23\n","     the loss is the cross entropy, so we need to maximize the log likelihood of it by\n","     computing its gradian. The derivation start with cross entropy and end with:\n","     gradient = np.dot(X.T, (y_pred - y)), m for avrage (1/m)\n","    \"\"\"\n","\n","    for _ in tqdm(range(n_iters)):\n","        z = np.dot(X, theta)\n","        y_pred = sigmoid(z)\n","        gradient = np.dot(X.T, (y_pred - y)) / m\n","        theta -= learning_rate * gradient\n","\n","        loss = log_reg_cost(y, y_pred)\n","        losses.append(loss)\n","\n","    plt.plot(losses)\n","\n","    return theta"],"metadata":{"id":"iOcH-9GyLHN5","executionInfo":{"status":"ok","timestamp":1700541904615,"user_tz":-180,"elapsed":3,"user":{"displayName":"am4 _m03","userId":"03884497344136522816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["num_data=100 # data points per class\n","\n","x1=np.random.randn(2,num_data)+5\n","x0=np.random.randn(2,num_data)\n","\n","y1=np.ones((1,num_data))\n","y0=np.zeros((1,num_data))\n","\n","\n","\n"],"metadata":{"id":"YZZdJm8gLJLB","executionInfo":{"status":"ok","timestamp":1700542191582,"user_tz":-180,"elapsed":329,"user":{"displayName":"am4 _m03","userId":"03884497344136522816"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["X=np.concatenate((x1,x0),axis=1)\n","y=np.concatenate((y1,y0), axis=1).squeeze()\n","X = X.T\n","y = y.T\n","print(X.shape)\n","print(y.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8L9J5VjYNqkQ","executionInfo":{"status":"ok","timestamp":1700542287081,"user_tz":-180,"elapsed":285,"user":{"displayName":"am4 _m03","userId":"03884497344136522816"}},"outputId":"5bc93987-5c79-4f22-bfa2-28a4a81759a5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["(200, 2)\n","(200,)\n"]}]},{"cell_type":"code","source":["n_point = num_data *2\n","max_coordinate_value = 10\n","points = X\n","l = np.sin(2*math.pi*(points[:, 0]/max_coordinate_value))\n","l = (l*0.3*max_coordinate_value) + (max_coordinate_value/2)\n","divider = (30 * np.sin(2*math.pi*np.linspace(0, max_coordinate_value, max_coordinate_value)/max_coordinate_value))\n","divider = max_coordinate_value/2 + divider\n"],"metadata":{"id":"wg7S-1X4LidU","executionInfo":{"status":"ok","timestamp":1700542292933,"user_tz":-180,"elapsed":267,"user":{"displayName":"am4 _m03","userId":"03884497344136522816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["num_iters = 30000\n","lr =1e-3\n","theta = log_reg_gradient_descent(X, y, lr, num_iters)\n","y_pred = sigmoid(np.dot(X, theta))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"ydv6l8dpMj1l","executionInfo":{"status":"error","timestamp":1700542529588,"user_tz":-180,"elapsed":627,"user":{"displayName":"am4 _m03","userId":"03884497344136522816"}},"outputId":"81c6f42a-2534-4987-fcef-76426e4bf69e"},"execution_count":18,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-1199789615b8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-b3ea95a10b93>\u001b[0m in \u001b[0;36mlog_reg_gradient_descent\u001b[0;34m(X, y, learning_rate, n_iters)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mRuns\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlogistic\u001b[0m \u001b[0mregression\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0moptimized\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;31m#m: the number of samples, n: the number of features in x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# theta is initialized with zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZBQN78nZNAdC"},"execution_count":null,"outputs":[]}]}